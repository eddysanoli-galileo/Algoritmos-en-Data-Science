{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "658dc12c475a3a8caebf03b24f414cffa2901ebd330ffd26b9c22f028a90850c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Hoja de Trabajo 1\n",
    "\n",
    "## Ejercicio 4 \n",
    "\n",
    "### Inciso C\n",
    "\n",
    "Utilizando cualquier software, resuelva el problema de optimización planteado en el inciso anterior. ¿Qué tipo de solución (global o local) encontró? Justifique su respuesta"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\eddys\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Enabled compatitility to tf1.x\n"
     ]
    }
   ],
   "source": [
    "# Para activar los gráficos interactivos\n",
    "%matplotlib widget\n",
    "\n",
    "# Paquetes a utilizar\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Habilitar la compatibilidad con tensorflow v1 si se tienen tensorflow v2\n",
    "if tf.__version__.startswith(\"2.\"):\n",
    "  import tensorflow.compat.v1 as tf\n",
    "  tf.compat.v1.disable_v2_behavior()\n",
    "  tf.compat.v1.disable_eager_execution()\n",
    "  print(\"Enabled compatitility to tf1.x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de función encargada de crear un grafo para hacer una regresión lineal\n",
    "def Create_LinRegGraph(NumFilas, NumParams):\n",
    "\n",
    "    # Se reinicia la creación del grafo creado\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # Se crea un objeto de tipo grafo\n",
    "    grafo = tf.Graph()\n",
    "\n",
    "    # Se incluyen nodos dentro del grafo\n",
    "    with grafo.as_default():\n",
    "\n",
    "        # Input: Se definen los datos de entrenamiento\n",
    "        # X: Tantas filas como datos (None para un tamaño variable). Tantas columnas como features\n",
    "        # Y: Tantas filas como datos (None para un tamaño variable). 1 Columna\n",
    "        X = tf.placeholder(tf.float32, [None, NumParams], \"X\")\n",
    "        Y = tf.placeholder(tf.float32, [None, 1], \"Y\")\n",
    "\n",
    "        # Input: Learning rate \n",
    "        learning_rate = tf.placeholder(dtype=\"float\", name=\"lr\")\n",
    "\n",
    "        # Se inicializan los parámetros correspondientes a las pendientes (m's) y el bias\n",
    "        params = tf.Variable(tf.zeros((NumParams, 1)), name=\"Theta\", dtype=tf.float32)\n",
    "\n",
    "        # Predicción de la salida dados los parámetros M y B\n",
    "        with tf.name_scope(\"Predict\"):\n",
    "            Y_hat = tf.matmul(X, params)\n",
    "\n",
    "        # Cálculo del error \n",
    "        with tf.name_scope(\"Error\"):\n",
    "            error = tf.reduce_sum(tf.pow(Y_hat - Y, 2)) / (2 * NumFilas)\n",
    "\n",
    "            # Incluir el error en la parte de \"Scalars\" de tensorboard\n",
    "            error_summary = tf.summary.scalar(\"Error\", error)\n",
    "\n",
    "        # Obtener el valor de los gradientes para M y B\n",
    "        grads_params = tf.gradients(error, params)\n",
    "\n",
    "        # La operación de gradiente es acoplada a un print para facilitar el debugging\n",
    "        # grads_print = tf.tuple(grads_params, control_inputs=[tf.print(grads_params)])\n",
    "        grads_print = tf.tuple(grads_params, control_inputs=[])\n",
    "\n",
    "        # El gradiente retorna un tensor de más dimensiones de las que regresó. \n",
    "        # Ejemplo: Para un tensor de \"params\" 2D, tf.gradients retorna un tensor 3D con 2 elementos.\n",
    "        # Se \"aplanan\" los datos para regresar a la forma original de params\n",
    "        grads = tf.reshape(grads_print[0], tf.shape(params))\n",
    "\n",
    "        # Actualizar los parámetros del algoritmo\n",
    "        with tf.name_scope(\"Update\"):\n",
    "            delta_params = tf.assign(params, params - learning_rate * grads)\n",
    "\n",
    "        # Inicializar variables globales\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "    return grafo, init, [X, Y], [learning_rate, delta_params, error_summary, params, error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de entrenamiento\n",
    "def Train(x, y, lr, epochs, metadata):\n",
    "\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "    # Se agrega una columna de 1's a X\n",
    "    x = np.hstack((x, np.ones((x.shape[0],1))))\n",
    "\n",
    "    # Se extraen las dimensiones de los datos de entrada\n",
    "    num_fil = x.shape[0]\n",
    "    num_col = x.shape[1]\n",
    "\n",
    "    # Se crea un grafo nuevo con el número de columnas de X\n",
    "    grafo, init, linRegIO, Nodes = Create_LinRegGraph(num_fil, num_col)\n",
    "\n",
    "    # Datos de entrenamiento (X) y labels (Y)\n",
    "    X, Y = linRegIO\n",
    "\n",
    "    # Se extrae la definición de los diferentes nodos utilizados luegos por TF\n",
    "    learning_rate = Nodes[0]\n",
    "    delta_params = Nodes[1]\n",
    "    error_summary = Nodes[2]\n",
    "    params = Nodes[3]\n",
    "    costo = Nodes[4]\n",
    "\n",
    "    with tf.Session(graph = grafo) as sess:\n",
    "        \n",
    "        # Inicializa todas las variables de ser necesario\n",
    "        tf.initialize_all_variables().run()\n",
    "\n",
    "        # Crea un directorio para tensorboard\n",
    "        # Generalmente el directorio \"padre\" de tensorboard es \"graphs\" pero puede cambiarse\n",
    "        writer = tf.summary.FileWriter((f'./graphs/{metadata}  model_lr={str(lr)}, epochs={str(epochs)}, no_feat={str(num_col)}'), sess.graph)\n",
    "\n",
    "        # Inicializar el grafo\n",
    "        sess.run(init)\n",
    "\n",
    "        # Se definen los inputs del grafo\n",
    "        inputs_grafo = {\n",
    "            X: x,\n",
    "            Y: y,\n",
    "            learning_rate: lr\n",
    "        }\n",
    "\n",
    "        # Iterar para cada Epoch\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            # Se corre el grafo con los datos elegidos\n",
    "            sess.run(delta_params, feed_dict=inputs_grafo)\n",
    "\n",
    "            # Se agregan todos los escalares al tensorboard\n",
    "            e = sess.run(error_summary, feed_dict=inputs_grafo)\n",
    "            writer.add_summary(e, epoch)\n",
    "        \n",
    "        # Se extraen los parámetros resultantes de la regresión y el error\n",
    "        theta = params.eval()\n",
    "        error = costo.eval(feed_dict=inputs_grafo)\n",
    "            \n",
    "        # Finalizar el \"writer\" hacia tensor board\n",
    "        writer.close()\n",
    "\n",
    "    return theta, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se convierten los arrays unidimensionales de numpy en arrays bidimensionales\n",
    "x_train = np.array([[16, 140],\n",
    "                    [25, 149],\n",
    "                    [39, 165],\n",
    "                    [45, 170],\n",
    "                    [49, 165],\n",
    "                    [64, 159],\n",
    "                    [70, 144]])\n",
    "y_train = np.array([[125, 129, 127, 150, 161, 144, 132]]).T\n",
    "\n",
    "# Se realiza el entrenamiento\n",
    "params, error = Train(x=x_train, y=y_train, lr=0.00001, epochs=500, metadata=\"HT1_4C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7986af40f7e14a23a86ccbfd5656be44"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Se crea una figura 3D\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "# Datos simulados de modelo lineal\n",
    "x1_model = np.linspace(min(x_train[:,0]), max(x_train[:,0]) + 1, 100)\n",
    "x2_model = np.linspace(min(x_train[:,1]), max(x_train[:,1]) + 1, 100)\n",
    "y_model = params[0,0] * x1_model + params[1,0] * x2_model + params[2,0]\n",
    "\n",
    "# Gráficas\n",
    "data = ax.scatter(xs=x_train[:,0], ys=x_train[:,1], zs=y_train, label=\"Data\")\n",
    "model = ax.scatter(xs=x1_model, ys=x2_model, zs=y_model, c=\"r\", s=0.8, label=\"Regresión\")\n",
    "\n",
    "# Títulos\n",
    "plt.title(\"Resultado Regresión\")\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.legend(handles=[data, model])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}